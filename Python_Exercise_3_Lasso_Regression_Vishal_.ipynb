{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Exercise 3 - Lasso Regression - Vishal .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishaln94/Digital-Advertising-Analytics/blob/master/Python_Exercise_3_Lasso_Regression_Vishal_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ZVPjxP0ZAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYhnVD272eVX",
        "colab_type": "code",
        "outputId": "4d8a97f3-cf7f-405d-d139-150b1420965e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko8WZ5554LS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZwrGnUu3bnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvfile = 'drive/My Drive/Colab Notebooks/finalmaster-ratios.csv'\n",
        "alldata = pd.read_csv(csvfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmTflkc-3vr8",
        "colab_type": "code",
        "outputId": "486858da-8faf-4d54-d7bf-5cfa9fccf9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "alldata.head(10)\n",
        "allvariablenames = list(alldata.columns.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># Purchases</th>\n",
              "      <th>B01001001</th>\n",
              "      <th>B01001002</th>\n",
              "      <th>B01001003</th>\n",
              "      <th>B01001004</th>\n",
              "      <th>B01001005</th>\n",
              "      <th>B01001006</th>\n",
              "      <th>B01001007</th>\n",
              "      <th>B01001008</th>\n",
              "      <th>B01001009</th>\n",
              "      <th>B01001010</th>\n",
              "      <th>B01001011</th>\n",
              "      <th>B01001012</th>\n",
              "      <th>B01001013</th>\n",
              "      <th>B01001014</th>\n",
              "      <th>B01001015</th>\n",
              "      <th>B01001016</th>\n",
              "      <th>B01001017</th>\n",
              "      <th>B01001018</th>\n",
              "      <th>B01001019</th>\n",
              "      <th>B01001020</th>\n",
              "      <th>B01001021</th>\n",
              "      <th>B01001022</th>\n",
              "      <th>B01001023</th>\n",
              "      <th>B01001024</th>\n",
              "      <th>B01001025</th>\n",
              "      <th>B01001026</th>\n",
              "      <th>B01001027</th>\n",
              "      <th>B01001028</th>\n",
              "      <th>B01001029</th>\n",
              "      <th>B01001030</th>\n",
              "      <th>B01001031</th>\n",
              "      <th>B01001032</th>\n",
              "      <th>B01001033</th>\n",
              "      <th>B01001034</th>\n",
              "      <th>B01001035</th>\n",
              "      <th>B01001036</th>\n",
              "      <th>B01001037</th>\n",
              "      <th>B01001038</th>\n",
              "      <th>B01001039</th>\n",
              "      <th>...</th>\n",
              "      <th>B15002013</th>\n",
              "      <th>B15002014</th>\n",
              "      <th>B15002015</th>\n",
              "      <th>B15002016</th>\n",
              "      <th>B15002017</th>\n",
              "      <th>B15002018</th>\n",
              "      <th>B15002019</th>\n",
              "      <th>B15002020</th>\n",
              "      <th>B15002021</th>\n",
              "      <th>B15002022</th>\n",
              "      <th>B15002023</th>\n",
              "      <th>B15002024</th>\n",
              "      <th>B15002025</th>\n",
              "      <th>B15002026</th>\n",
              "      <th>B15002027</th>\n",
              "      <th>B15002028</th>\n",
              "      <th>B15002029</th>\n",
              "      <th>B15002030</th>\n",
              "      <th>B15002031</th>\n",
              "      <th>B15002032</th>\n",
              "      <th>B15002033</th>\n",
              "      <th>B15002034</th>\n",
              "      <th>B15002035</th>\n",
              "      <th>B19001001</th>\n",
              "      <th>B19001002</th>\n",
              "      <th>B19001003</th>\n",
              "      <th>B19001004</th>\n",
              "      <th>B19001005</th>\n",
              "      <th>B19001006</th>\n",
              "      <th>B19001007</th>\n",
              "      <th>B19001008</th>\n",
              "      <th>B19001009</th>\n",
              "      <th>B19001010</th>\n",
              "      <th>B19001011</th>\n",
              "      <th>B19001012</th>\n",
              "      <th>B19001013</th>\n",
              "      <th>B19001014</th>\n",
              "      <th>B19001015</th>\n",
              "      <th>B19001016</th>\n",
              "      <th>B19001017</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>206252</td>\n",
              "      <td>469.226965</td>\n",
              "      <td>31.432422</td>\n",
              "      <td>35.219052</td>\n",
              "      <td>33.628765</td>\n",
              "      <td>20.121017</td>\n",
              "      <td>12.610787</td>\n",
              "      <td>6.734480</td>\n",
              "      <td>6.225394</td>\n",
              "      <td>19.432539</td>\n",
              "      <td>28.101546</td>\n",
              "      <td>28.421543</td>\n",
              "      <td>26.390047</td>\n",
              "      <td>31.989993</td>\n",
              "      <td>31.359696</td>\n",
              "      <td>32.116052</td>\n",
              "      <td>32.213021</td>\n",
              "      <td>12.184124</td>\n",
              "      <td>18.361034</td>\n",
              "      <td>9.454454</td>\n",
              "      <td>15.175610</td>\n",
              "      <td>16.281054</td>\n",
              "      <td>11.025348</td>\n",
              "      <td>6.230243</td>\n",
              "      <td>4.518744</td>\n",
              "      <td>530.773035</td>\n",
              "      <td>31.999690</td>\n",
              "      <td>34.322091</td>\n",
              "      <td>32.649380</td>\n",
              "      <td>20.101623</td>\n",
              "      <td>12.513818</td>\n",
              "      <td>8.072649</td>\n",
              "      <td>6.021760</td>\n",
              "      <td>22.923414</td>\n",
              "      <td>31.335454</td>\n",
              "      <td>31.558482</td>\n",
              "      <td>31.063941</td>\n",
              "      <td>36.082074</td>\n",
              "      <td>34.845723</td>\n",
              "      <td>...</td>\n",
              "      <td>64.610300</td>\n",
              "      <td>31.449746</td>\n",
              "      <td>58.735313</td>\n",
              "      <td>20.071053</td>\n",
              "      <td>6.726751</td>\n",
              "      <td>5.882267</td>\n",
              "      <td>543.803963</td>\n",
              "      <td>6.974272</td>\n",
              "      <td>2.504332</td>\n",
              "      <td>5.904107</td>\n",
              "      <td>11.917415</td>\n",
              "      <td>10.767170</td>\n",
              "      <td>18.141844</td>\n",
              "      <td>19.779852</td>\n",
              "      <td>10.956451</td>\n",
              "      <td>181.418442</td>\n",
              "      <td>26.717724</td>\n",
              "      <td>85.271036</td>\n",
              "      <td>54.243532</td>\n",
              "      <td>72.647457</td>\n",
              "      <td>30.816383</td>\n",
              "      <td>2.831933</td>\n",
              "      <td>2.912014</td>\n",
              "      <td>1000</td>\n",
              "      <td>105.667996</td>\n",
              "      <td>82.298375</td>\n",
              "      <td>68.141163</td>\n",
              "      <td>67.336195</td>\n",
              "      <td>63.566902</td>\n",
              "      <td>59.439845</td>\n",
              "      <td>49.409690</td>\n",
              "      <td>53.306757</td>\n",
              "      <td>42.318307</td>\n",
              "      <td>83.167229</td>\n",
              "      <td>89.249208</td>\n",
              "      <td>102.141470</td>\n",
              "      <td>52.872330</td>\n",
              "      <td>36.440765</td>\n",
              "      <td>23.446284</td>\n",
              "      <td>21.197485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>61399</td>\n",
              "      <td>486.538869</td>\n",
              "      <td>22.899396</td>\n",
              "      <td>21.531295</td>\n",
              "      <td>27.036271</td>\n",
              "      <td>16.808091</td>\n",
              "      <td>28.355511</td>\n",
              "      <td>18.192479</td>\n",
              "      <td>13.534422</td>\n",
              "      <td>21.466148</td>\n",
              "      <td>24.886399</td>\n",
              "      <td>23.534585</td>\n",
              "      <td>21.319565</td>\n",
              "      <td>27.101419</td>\n",
              "      <td>30.961416</td>\n",
              "      <td>37.117868</td>\n",
              "      <td>36.466392</td>\n",
              "      <td>12.557208</td>\n",
              "      <td>20.554081</td>\n",
              "      <td>12.182609</td>\n",
              "      <td>15.651721</td>\n",
              "      <td>20.668089</td>\n",
              "      <td>15.961172</td>\n",
              "      <td>10.423623</td>\n",
              "      <td>7.329110</td>\n",
              "      <td>513.461131</td>\n",
              "      <td>18.974250</td>\n",
              "      <td>23.404290</td>\n",
              "      <td>23.892897</td>\n",
              "      <td>17.036108</td>\n",
              "      <td>35.310021</td>\n",
              "      <td>18.534504</td>\n",
              "      <td>17.101256</td>\n",
              "      <td>22.785387</td>\n",
              "      <td>22.150198</td>\n",
              "      <td>22.622518</td>\n",
              "      <td>21.303279</td>\n",
              "      <td>26.971123</td>\n",
              "      <td>32.329517</td>\n",
              "      <td>...</td>\n",
              "      <td>56.929829</td>\n",
              "      <td>46.381727</td>\n",
              "      <td>65.707446</td>\n",
              "      <td>35.509451</td>\n",
              "      <td>16.782205</td>\n",
              "      <td>9.201536</td>\n",
              "      <td>515.086529</td>\n",
              "      <td>3.017306</td>\n",
              "      <td>1.047329</td>\n",
              "      <td>1.371503</td>\n",
              "      <td>6.358785</td>\n",
              "      <td>4.937410</td>\n",
              "      <td>8.303825</td>\n",
              "      <td>9.700264</td>\n",
              "      <td>7.555733</td>\n",
              "      <td>174.155902</td>\n",
              "      <td>25.834123</td>\n",
              "      <td>60.146626</td>\n",
              "      <td>62.440776</td>\n",
              "      <td>76.604658</td>\n",
              "      <td>55.383771</td>\n",
              "      <td>8.977108</td>\n",
              "      <td>9.251409</td>\n",
              "      <td>1000</td>\n",
              "      <td>71.289558</td>\n",
              "      <td>59.062447</td>\n",
              "      <td>54.704688</td>\n",
              "      <td>60.966323</td>\n",
              "      <td>53.012354</td>\n",
              "      <td>60.881706</td>\n",
              "      <td>59.231680</td>\n",
              "      <td>50.093078</td>\n",
              "      <td>40.700626</td>\n",
              "      <td>92.612963</td>\n",
              "      <td>117.363344</td>\n",
              "      <td>113.344051</td>\n",
              "      <td>75.774243</td>\n",
              "      <td>33.000508</td>\n",
              "      <td>33.169741</td>\n",
              "      <td>24.792689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>73170</td>\n",
              "      <td>489.859232</td>\n",
              "      <td>28.905289</td>\n",
              "      <td>36.271696</td>\n",
              "      <td>28.235616</td>\n",
              "      <td>21.566216</td>\n",
              "      <td>12.218122</td>\n",
              "      <td>7.243406</td>\n",
              "      <td>7.380074</td>\n",
              "      <td>16.933169</td>\n",
              "      <td>24.914582</td>\n",
              "      <td>26.896269</td>\n",
              "      <td>31.802651</td>\n",
              "      <td>30.531639</td>\n",
              "      <td>36.258029</td>\n",
              "      <td>35.998360</td>\n",
              "      <td>33.429001</td>\n",
              "      <td>13.625803</td>\n",
              "      <td>19.406861</td>\n",
              "      <td>12.245456</td>\n",
              "      <td>14.664480</td>\n",
              "      <td>21.169878</td>\n",
              "      <td>15.293153</td>\n",
              "      <td>8.610086</td>\n",
              "      <td>6.259396</td>\n",
              "      <td>510.140768</td>\n",
              "      <td>26.171928</td>\n",
              "      <td>30.681973</td>\n",
              "      <td>31.925653</td>\n",
              "      <td>19.789531</td>\n",
              "      <td>10.072434</td>\n",
              "      <td>5.056717</td>\n",
              "      <td>6.218396</td>\n",
              "      <td>15.757824</td>\n",
              "      <td>24.449911</td>\n",
              "      <td>26.595599</td>\n",
              "      <td>27.210605</td>\n",
              "      <td>37.556376</td>\n",
              "      <td>37.050704</td>\n",
              "      <td>...</td>\n",
              "      <td>54.602613</td>\n",
              "      <td>40.613027</td>\n",
              "      <td>43.363788</td>\n",
              "      <td>12.280185</td>\n",
              "      <td>5.796247</td>\n",
              "      <td>3.438452</td>\n",
              "      <td>523.980745</td>\n",
              "      <td>5.422930</td>\n",
              "      <td>4.224384</td>\n",
              "      <td>11.828274</td>\n",
              "      <td>18.331860</td>\n",
              "      <td>15.089891</td>\n",
              "      <td>21.731015</td>\n",
              "      <td>18.685529</td>\n",
              "      <td>7.014441</td>\n",
              "      <td>155.241183</td>\n",
              "      <td>45.466156</td>\n",
              "      <td>71.185775</td>\n",
              "      <td>65.802142</td>\n",
              "      <td>56.272718</td>\n",
              "      <td>24.580018</td>\n",
              "      <td>1.689753</td>\n",
              "      <td>1.414677</td>\n",
              "      <td>1000</td>\n",
              "      <td>102.538696</td>\n",
              "      <td>82.960331</td>\n",
              "      <td>74.828305</td>\n",
              "      <td>79.133495</td>\n",
              "      <td>66.081252</td>\n",
              "      <td>78.245122</td>\n",
              "      <td>63.996993</td>\n",
              "      <td>47.322923</td>\n",
              "      <td>42.505211</td>\n",
              "      <td>70.420610</td>\n",
              "      <td>90.033143</td>\n",
              "      <td>98.677692</td>\n",
              "      <td>54.703249</td>\n",
              "      <td>20.125056</td>\n",
              "      <td>11.890525</td>\n",
              "      <td>16.537397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94</td>\n",
              "      <td>251724</td>\n",
              "      <td>505.585483</td>\n",
              "      <td>32.054949</td>\n",
              "      <td>31.757004</td>\n",
              "      <td>28.102207</td>\n",
              "      <td>18.651380</td>\n",
              "      <td>12.080692</td>\n",
              "      <td>7.035483</td>\n",
              "      <td>7.686991</td>\n",
              "      <td>25.790151</td>\n",
              "      <td>42.129475</td>\n",
              "      <td>35.824951</td>\n",
              "      <td>32.058922</td>\n",
              "      <td>27.677138</td>\n",
              "      <td>33.842621</td>\n",
              "      <td>38.176733</td>\n",
              "      <td>32.722347</td>\n",
              "      <td>12.493842</td>\n",
              "      <td>16.394940</td>\n",
              "      <td>11.504664</td>\n",
              "      <td>15.914255</td>\n",
              "      <td>16.394940</td>\n",
              "      <td>13.196994</td>\n",
              "      <td>8.648361</td>\n",
              "      <td>5.446441</td>\n",
              "      <td>494.414517</td>\n",
              "      <td>33.123580</td>\n",
              "      <td>28.082344</td>\n",
              "      <td>30.171934</td>\n",
              "      <td>16.863708</td>\n",
              "      <td>9.280005</td>\n",
              "      <td>5.390825</td>\n",
              "      <td>5.609318</td>\n",
              "      <td>19.453846</td>\n",
              "      <td>35.614403</td>\n",
              "      <td>32.082757</td>\n",
              "      <td>28.809331</td>\n",
              "      <td>27.911522</td>\n",
              "      <td>32.690566</td>\n",
              "      <td>...</td>\n",
              "      <td>88.227492</td>\n",
              "      <td>44.076261</td>\n",
              "      <td>87.939148</td>\n",
              "      <td>44.404973</td>\n",
              "      <td>9.671057</td>\n",
              "      <td>7.283569</td>\n",
              "      <td>502.912274</td>\n",
              "      <td>4.509700</td>\n",
              "      <td>0.980370</td>\n",
              "      <td>3.552398</td>\n",
              "      <td>5.986021</td>\n",
              "      <td>7.398907</td>\n",
              "      <td>9.740260</td>\n",
              "      <td>10.605292</td>\n",
              "      <td>7.485410</td>\n",
              "      <td>141.242417</td>\n",
              "      <td>43.078591</td>\n",
              "      <td>84.479020</td>\n",
              "      <td>52.069156</td>\n",
              "      <td>89.836451</td>\n",
              "      <td>33.932320</td>\n",
              "      <td>4.129086</td>\n",
              "      <td>3.886877</td>\n",
              "      <td>1000</td>\n",
              "      <td>61.632139</td>\n",
              "      <td>46.526521</td>\n",
              "      <td>48.437595</td>\n",
              "      <td>54.221644</td>\n",
              "      <td>51.680322</td>\n",
              "      <td>60.066684</td>\n",
              "      <td>54.790900</td>\n",
              "      <td>48.681562</td>\n",
              "      <td>43.873381</td>\n",
              "      <td>84.717507</td>\n",
              "      <td>112.204444</td>\n",
              "      <td>127.137252</td>\n",
              "      <td>83.019904</td>\n",
              "      <td>43.731067</td>\n",
              "      <td>38.851729</td>\n",
              "      <td>40.427349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>37382</td>\n",
              "      <td>495.586111</td>\n",
              "      <td>25.413301</td>\n",
              "      <td>29.318924</td>\n",
              "      <td>26.162324</td>\n",
              "      <td>19.260607</td>\n",
              "      <td>12.893906</td>\n",
              "      <td>6.580707</td>\n",
              "      <td>7.062222</td>\n",
              "      <td>17.334546</td>\n",
              "      <td>32.930287</td>\n",
              "      <td>28.302392</td>\n",
              "      <td>28.569900</td>\n",
              "      <td>26.804344</td>\n",
              "      <td>30.549462</td>\n",
              "      <td>36.595153</td>\n",
              "      <td>42.373335</td>\n",
              "      <td>16.398267</td>\n",
              "      <td>22.871970</td>\n",
              "      <td>17.174041</td>\n",
              "      <td>15.221229</td>\n",
              "      <td>23.433738</td>\n",
              "      <td>14.391953</td>\n",
              "      <td>7.383233</td>\n",
              "      <td>8.560270</td>\n",
              "      <td>504.413889</td>\n",
              "      <td>26.563587</td>\n",
              "      <td>30.255203</td>\n",
              "      <td>24.798031</td>\n",
              "      <td>16.237761</td>\n",
              "      <td>11.101600</td>\n",
              "      <td>4.788401</td>\n",
              "      <td>5.189663</td>\n",
              "      <td>17.842812</td>\n",
              "      <td>30.014445</td>\n",
              "      <td>27.767375</td>\n",
              "      <td>30.763469</td>\n",
              "      <td>25.199294</td>\n",
              "      <td>29.613183</td>\n",
              "      <td>...</td>\n",
              "      <td>102.957039</td>\n",
              "      <td>36.711921</td>\n",
              "      <td>70.039055</td>\n",
              "      <td>33.587502</td>\n",
              "      <td>5.021387</td>\n",
              "      <td>5.244560</td>\n",
              "      <td>511.177236</td>\n",
              "      <td>2.045750</td>\n",
              "      <td>3.236005</td>\n",
              "      <td>1.525014</td>\n",
              "      <td>7.476288</td>\n",
              "      <td>4.314674</td>\n",
              "      <td>8.554956</td>\n",
              "      <td>13.204389</td>\n",
              "      <td>7.773852</td>\n",
              "      <td>130.890831</td>\n",
              "      <td>53.784638</td>\n",
              "      <td>99.311884</td>\n",
              "      <td>57.095034</td>\n",
              "      <td>76.027525</td>\n",
              "      <td>38.422912</td>\n",
              "      <td>4.351869</td>\n",
              "      <td>3.161614</td>\n",
              "      <td>1000</td>\n",
              "      <td>51.125525</td>\n",
              "      <td>58.438255</td>\n",
              "      <td>68.930434</td>\n",
              "      <td>74.717029</td>\n",
              "      <td>63.970495</td>\n",
              "      <td>59.710034</td>\n",
              "      <td>58.883378</td>\n",
              "      <td>51.761414</td>\n",
              "      <td>47.310187</td>\n",
              "      <td>81.902582</td>\n",
              "      <td>93.793717</td>\n",
              "      <td>130.103014</td>\n",
              "      <td>71.982704</td>\n",
              "      <td>36.118530</td>\n",
              "      <td>31.603714</td>\n",
              "      <td>19.648989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>19</td>\n",
              "      <td>230108</td>\n",
              "      <td>499.217759</td>\n",
              "      <td>32.767222</td>\n",
              "      <td>35.465955</td>\n",
              "      <td>36.169972</td>\n",
              "      <td>22.107011</td>\n",
              "      <td>13.593617</td>\n",
              "      <td>5.671250</td>\n",
              "      <td>6.144941</td>\n",
              "      <td>19.069307</td>\n",
              "      <td>31.141899</td>\n",
              "      <td>34.296939</td>\n",
              "      <td>33.162689</td>\n",
              "      <td>32.515167</td>\n",
              "      <td>38.034314</td>\n",
              "      <td>40.168095</td>\n",
              "      <td>35.448572</td>\n",
              "      <td>11.920490</td>\n",
              "      <td>15.331931</td>\n",
              "      <td>8.535123</td>\n",
              "      <td>10.564604</td>\n",
              "      <td>14.475811</td>\n",
              "      <td>10.477689</td>\n",
              "      <td>6.509987</td>\n",
              "      <td>5.645175</td>\n",
              "      <td>500.782241</td>\n",
              "      <td>31.185356</td>\n",
              "      <td>33.466894</td>\n",
              "      <td>34.774975</td>\n",
              "      <td>20.629444</td>\n",
              "      <td>11.942218</td>\n",
              "      <td>6.570828</td>\n",
              "      <td>5.714708</td>\n",
              "      <td>16.444452</td>\n",
              "      <td>30.911572</td>\n",
              "      <td>33.119231</td>\n",
              "      <td>31.945869</td>\n",
              "      <td>32.567316</td>\n",
              "      <td>38.060389</td>\n",
              "      <td>...</td>\n",
              "      <td>65.673020</td>\n",
              "      <td>57.466331</td>\n",
              "      <td>92.510584</td>\n",
              "      <td>27.266756</td>\n",
              "      <td>7.497870</td>\n",
              "      <td>4.246409</td>\n",
              "      <td>508.847227</td>\n",
              "      <td>4.051321</td>\n",
              "      <td>0.747836</td>\n",
              "      <td>1.222550</td>\n",
              "      <td>6.054221</td>\n",
              "      <td>3.186432</td>\n",
              "      <td>4.714619</td>\n",
              "      <td>3.830222</td>\n",
              "      <td>6.678502</td>\n",
              "      <td>167.924982</td>\n",
              "      <td>35.284861</td>\n",
              "      <td>67.370283</td>\n",
              "      <td>60.691781</td>\n",
              "      <td>106.647938</td>\n",
              "      <td>33.073867</td>\n",
              "      <td>4.877192</td>\n",
              "      <td>2.490620</td>\n",
              "      <td>1000</td>\n",
              "      <td>37.681843</td>\n",
              "      <td>39.309447</td>\n",
              "      <td>43.473869</td>\n",
              "      <td>48.558728</td>\n",
              "      <td>44.495330</td>\n",
              "      <td>48.188308</td>\n",
              "      <td>46.201509</td>\n",
              "      <td>46.504580</td>\n",
              "      <td>47.750539</td>\n",
              "      <td>90.247845</td>\n",
              "      <td>122.294810</td>\n",
              "      <td>160.998114</td>\n",
              "      <td>100.372665</td>\n",
              "      <td>56.045708</td>\n",
              "      <td>39.017601</td>\n",
              "      <td>28.859106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>928405</td>\n",
              "      <td>493.339652</td>\n",
              "      <td>28.576968</td>\n",
              "      <td>30.484541</td>\n",
              "      <td>33.556476</td>\n",
              "      <td>21.172872</td>\n",
              "      <td>15.826067</td>\n",
              "      <td>7.983585</td>\n",
              "      <td>7.764930</td>\n",
              "      <td>19.890026</td>\n",
              "      <td>31.149121</td>\n",
              "      <td>29.757487</td>\n",
              "      <td>29.253397</td>\n",
              "      <td>34.082109</td>\n",
              "      <td>38.370108</td>\n",
              "      <td>40.453250</td>\n",
              "      <td>36.642414</td>\n",
              "      <td>12.309283</td>\n",
              "      <td>16.434638</td>\n",
              "      <td>9.640189</td>\n",
              "      <td>11.470210</td>\n",
              "      <td>14.666013</td>\n",
              "      <td>9.220114</td>\n",
              "      <td>7.295308</td>\n",
              "      <td>7.340546</td>\n",
              "      <td>506.660348</td>\n",
              "      <td>26.972065</td>\n",
              "      <td>28.499416</td>\n",
              "      <td>32.284402</td>\n",
              "      <td>20.009586</td>\n",
              "      <td>15.343519</td>\n",
              "      <td>7.624905</td>\n",
              "      <td>7.173593</td>\n",
              "      <td>18.603950</td>\n",
              "      <td>29.942751</td>\n",
              "      <td>30.008455</td>\n",
              "      <td>29.901821</td>\n",
              "      <td>35.774258</td>\n",
              "      <td>38.770795</td>\n",
              "      <td>...</td>\n",
              "      <td>56.613332</td>\n",
              "      <td>36.595069</td>\n",
              "      <td>98.787470</td>\n",
              "      <td>41.410251</td>\n",
              "      <td>9.352444</td>\n",
              "      <td>8.796601</td>\n",
              "      <td>516.266328</td>\n",
              "      <td>5.763291</td>\n",
              "      <td>2.280542</td>\n",
              "      <td>3.981419</td>\n",
              "      <td>8.872831</td>\n",
              "      <td>6.020566</td>\n",
              "      <td>9.025291</td>\n",
              "      <td>7.966014</td>\n",
              "      <td>7.299003</td>\n",
              "      <td>144.199786</td>\n",
              "      <td>31.683011</td>\n",
              "      <td>63.969508</td>\n",
              "      <td>54.048517</td>\n",
              "      <td>104.315718</td>\n",
              "      <td>52.900306</td>\n",
              "      <td>7.472109</td>\n",
              "      <td>6.468416</td>\n",
              "      <td>1000</td>\n",
              "      <td>56.155414</td>\n",
              "      <td>50.403529</td>\n",
              "      <td>47.395876</td>\n",
              "      <td>44.176904</td>\n",
              "      <td>40.190822</td>\n",
              "      <td>45.459282</td>\n",
              "      <td>37.631856</td>\n",
              "      <td>38.216597</td>\n",
              "      <td>35.938423</td>\n",
              "      <td>72.751062</td>\n",
              "      <td>98.274145</td>\n",
              "      <td>132.154395</td>\n",
              "      <td>102.318122</td>\n",
              "      <td>66.729965</td>\n",
              "      <td>71.766845</td>\n",
              "      <td>60.436761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>15890</td>\n",
              "      <td>498.237886</td>\n",
              "      <td>32.473254</td>\n",
              "      <td>34.675897</td>\n",
              "      <td>36.752675</td>\n",
              "      <td>26.557583</td>\n",
              "      <td>17.747011</td>\n",
              "      <td>4.845815</td>\n",
              "      <td>16.362492</td>\n",
              "      <td>20.264317</td>\n",
              "      <td>34.675897</td>\n",
              "      <td>33.731907</td>\n",
              "      <td>29.452486</td>\n",
              "      <td>31.843927</td>\n",
              "      <td>29.452486</td>\n",
              "      <td>30.396476</td>\n",
              "      <td>30.522341</td>\n",
              "      <td>2.643172</td>\n",
              "      <td>25.361863</td>\n",
              "      <td>8.999371</td>\n",
              "      <td>12.523600</td>\n",
              "      <td>16.551290</td>\n",
              "      <td>6.104468</td>\n",
              "      <td>7.174323</td>\n",
              "      <td>9.125236</td>\n",
              "      <td>501.762114</td>\n",
              "      <td>30.144745</td>\n",
              "      <td>34.046570</td>\n",
              "      <td>34.990560</td>\n",
              "      <td>22.089364</td>\n",
              "      <td>14.977974</td>\n",
              "      <td>9.880428</td>\n",
              "      <td>5.349276</td>\n",
              "      <td>21.837634</td>\n",
              "      <td>33.731907</td>\n",
              "      <td>32.662052</td>\n",
              "      <td>23.599748</td>\n",
              "      <td>38.577722</td>\n",
              "      <td>36.186281</td>\n",
              "      <td>...</td>\n",
              "      <td>64.018969</td>\n",
              "      <td>31.416716</td>\n",
              "      <td>39.715471</td>\n",
              "      <td>10.966212</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>515.609563</td>\n",
              "      <td>10.274649</td>\n",
              "      <td>43.667259</td>\n",
              "      <td>15.016795</td>\n",
              "      <td>13.930053</td>\n",
              "      <td>21.932424</td>\n",
              "      <td>5.927682</td>\n",
              "      <td>0.592768</td>\n",
              "      <td>1.185536</td>\n",
              "      <td>208.753211</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.645525</td>\n",
              "      <td>34.578147</td>\n",
              "      <td>78.838174</td>\n",
              "      <td>21.537246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.730093</td>\n",
              "      <td>1000</td>\n",
              "      <td>328.835375</td>\n",
              "      <td>143.035084</td>\n",
              "      <td>109.404194</td>\n",
              "      <td>91.135562</td>\n",
              "      <td>77.434088</td>\n",
              "      <td>88.644384</td>\n",
              "      <td>32.177704</td>\n",
              "      <td>30.309321</td>\n",
              "      <td>17.023043</td>\n",
              "      <td>15.569857</td>\n",
              "      <td>53.975503</td>\n",
              "      <td>12.455885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>24327</td>\n",
              "      <td>475.562133</td>\n",
              "      <td>30.007810</td>\n",
              "      <td>29.514531</td>\n",
              "      <td>31.158795</td>\n",
              "      <td>18.950138</td>\n",
              "      <td>27.335882</td>\n",
              "      <td>13.318535</td>\n",
              "      <td>16.771488</td>\n",
              "      <td>25.814938</td>\n",
              "      <td>26.308217</td>\n",
              "      <td>24.499527</td>\n",
              "      <td>20.594401</td>\n",
              "      <td>28.034694</td>\n",
              "      <td>27.541415</td>\n",
              "      <td>30.131130</td>\n",
              "      <td>22.814157</td>\n",
              "      <td>16.894808</td>\n",
              "      <td>18.292432</td>\n",
              "      <td>4.891684</td>\n",
              "      <td>11.797591</td>\n",
              "      <td>21.334320</td>\n",
              "      <td>10.934353</td>\n",
              "      <td>8.139105</td>\n",
              "      <td>10.482180</td>\n",
              "      <td>524.437867</td>\n",
              "      <td>29.514531</td>\n",
              "      <td>26.102684</td>\n",
              "      <td>32.885272</td>\n",
              "      <td>19.731163</td>\n",
              "      <td>33.460764</td>\n",
              "      <td>14.017347</td>\n",
              "      <td>10.646607</td>\n",
              "      <td>22.690837</td>\n",
              "      <td>29.637851</td>\n",
              "      <td>27.294775</td>\n",
              "      <td>30.131130</td>\n",
              "      <td>29.308998</td>\n",
              "      <td>30.213343</td>\n",
              "      <td>...</td>\n",
              "      <td>57.262570</td>\n",
              "      <td>25.538707</td>\n",
              "      <td>66.906092</td>\n",
              "      <td>19.553073</td>\n",
              "      <td>1.795690</td>\n",
              "      <td>5.653099</td>\n",
              "      <td>542.631019</td>\n",
              "      <td>2.061719</td>\n",
              "      <td>2.261240</td>\n",
              "      <td>6.384677</td>\n",
              "      <td>12.702846</td>\n",
              "      <td>20.949721</td>\n",
              "      <td>20.218143</td>\n",
              "      <td>17.158819</td>\n",
              "      <td>6.650705</td>\n",
              "      <td>191.074754</td>\n",
              "      <td>39.638202</td>\n",
              "      <td>75.219473</td>\n",
              "      <td>41.965948</td>\n",
              "      <td>66.374036</td>\n",
              "      <td>39.106145</td>\n",
              "      <td>0.864592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000</td>\n",
              "      <td>143.586537</td>\n",
              "      <td>107.012608</td>\n",
              "      <td>64.811920</td>\n",
              "      <td>58.976764</td>\n",
              "      <td>48.661040</td>\n",
              "      <td>57.517974</td>\n",
              "      <td>46.472856</td>\n",
              "      <td>53.871001</td>\n",
              "      <td>26.675003</td>\n",
              "      <td>64.707721</td>\n",
              "      <td>87.110555</td>\n",
              "      <td>108.679796</td>\n",
              "      <td>64.916120</td>\n",
              "      <td>40.637699</td>\n",
              "      <td>16.359279</td>\n",
              "      <td>10.003126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2861</td>\n",
              "      <td>19979950</td>\n",
              "      <td>483.276184</td>\n",
              "      <td>31.650830</td>\n",
              "      <td>30.824702</td>\n",
              "      <td>31.484864</td>\n",
              "      <td>19.676576</td>\n",
              "      <td>12.867249</td>\n",
              "      <td>6.957375</td>\n",
              "      <td>6.725342</td>\n",
              "      <td>20.587289</td>\n",
              "      <td>36.469210</td>\n",
              "      <td>34.933871</td>\n",
              "      <td>32.435116</td>\n",
              "      <td>33.524108</td>\n",
              "      <td>34.928115</td>\n",
              "      <td>35.261650</td>\n",
              "      <td>31.333612</td>\n",
              "      <td>11.143872</td>\n",
              "      <td>14.961499</td>\n",
              "      <td>8.889862</td>\n",
              "      <td>10.915393</td>\n",
              "      <td>13.836321</td>\n",
              "      <td>10.021697</td>\n",
              "      <td>7.261179</td>\n",
              "      <td>6.586453</td>\n",
              "      <td>516.723816</td>\n",
              "      <td>30.228554</td>\n",
              "      <td>29.519894</td>\n",
              "      <td>30.130256</td>\n",
              "      <td>18.782730</td>\n",
              "      <td>12.267498</td>\n",
              "      <td>6.739957</td>\n",
              "      <td>6.564281</td>\n",
              "      <td>20.636188</td>\n",
              "      <td>37.237781</td>\n",
              "      <td>36.016507</td>\n",
              "      <td>33.817602</td>\n",
              "      <td>35.177465</td>\n",
              "      <td>37.124718</td>\n",
              "      <td>...</td>\n",
              "      <td>56.259790</td>\n",
              "      <td>28.012770</td>\n",
              "      <td>104.830640</td>\n",
              "      <td>46.524615</td>\n",
              "      <td>16.989401</td>\n",
              "      <td>8.370920</td>\n",
              "      <td>528.751466</td>\n",
              "      <td>10.664496</td>\n",
              "      <td>6.246578</td>\n",
              "      <td>11.740088</td>\n",
              "      <td>11.277145</td>\n",
              "      <td>7.400862</td>\n",
              "      <td>8.240521</td>\n",
              "      <td>9.871790</td>\n",
              "      <td>11.377340</td>\n",
              "      <td>135.112851</td>\n",
              "      <td>21.647567</td>\n",
              "      <td>58.133719</td>\n",
              "      <td>38.371563</td>\n",
              "      <td>115.299940</td>\n",
              "      <td>63.956628</td>\n",
              "      <td>12.952002</td>\n",
              "      <td>6.458376</td>\n",
              "      <td>1000</td>\n",
              "      <td>72.572820</td>\n",
              "      <td>46.121401</td>\n",
              "      <td>44.665889</td>\n",
              "      <td>43.258684</td>\n",
              "      <td>39.156710</td>\n",
              "      <td>39.365804</td>\n",
              "      <td>36.342018</td>\n",
              "      <td>36.246108</td>\n",
              "      <td>31.909623</td>\n",
              "      <td>64.438383</td>\n",
              "      <td>87.488833</td>\n",
              "      <td>117.364952</td>\n",
              "      <td>93.519131</td>\n",
              "      <td>63.997025</td>\n",
              "      <td>80.800359</td>\n",
              "      <td>102.752258</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 190 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   # Purchases  B01001001   B01001002  ...  B19001015  B19001016   B19001017\n",
              "0           22     206252  469.226965  ...  36.440765  23.446284   21.197485\n",
              "1            7      61399  486.538869  ...  33.000508  33.169741   24.792689\n",
              "2            3      73170  489.859232  ...  20.125056  11.890525   16.537397\n",
              "3           94     251724  505.585483  ...  43.731067  38.851729   40.427349\n",
              "4            0      37382  495.586111  ...  36.118530  31.603714   19.648989\n",
              "5           19     230108  499.217759  ...  56.045708  39.017601   28.859106\n",
              "6           11     928405  493.339652  ...  66.729965  71.766845   60.436761\n",
              "7            2      15890  498.237886  ...   0.000000   0.000000    0.000000\n",
              "8            0      24327  475.562133  ...  40.637699  16.359279   10.003126\n",
              "9         2861   19979950  483.276184  ...  63.997025  80.800359  102.752258\n",
              "\n",
              "[10 rows x 190 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvzeqWQ4OiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del allvariablenames[0:8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA9Wgk4U6Wb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load predictors into dataframe\n",
        "predictors = alldata[allvariablenames]  \n",
        "#load target into dataframe\n",
        "target = alldata['# Purchases'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlF2aMwS7qHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into train and test sets, with 30% retained for test\n",
        "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2qsvJR6A-QF",
        "colab_type": "code",
        "outputId": "d09994e7-bf7d-440e-e180-dbb419c894e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LassoLarsCV(fit_intercept=True, verbose=False, max_iter=500, normalize=True, precompute=False, cv=10, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True, positive=False).fit(pred_train, tar_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.739e-01, previous alpha=5.739e-01, with an active set of 14 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.365e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.008e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.144e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.642e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.644e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.626e-01, previous alpha=5.354e-01, with an active set of 13 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.201e-01, previous alpha=7.200e-01, with an active set of 12 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=4.546e-02, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.539e-02, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 116 iterations, alpha=3.652e-02, previous alpha=3.599e-02, with an active set of 99 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.100e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.523e-02, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.523e-02, with an active set of 60 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.435e-02, previous alpha=6.382e-02, with an active set of 61 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.147e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.014e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.010e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.693e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.099e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.948e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.137e-01, previous alpha=3.116e-01, with an active set of 27 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.644e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.822e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=2.062e-01, previous alpha=1.984e-01, with an active set of 34 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.732e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.285e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.186e-01, previous alpha=5.185e-01, with an active set of 15 regressors.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG7gXZphnxBx",
        "colab_type": "text"
      },
      "source": [
        "Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYSqRJI7bLxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors_model=pd.DataFrame(allvariablenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBulGbZVb-ym",
        "colab_type": "text"
      },
      "source": [
        "In the first line of code, we are creating a dataframe of the list of all predictors in our dataset.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Woo5Q0bCbm-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors_model.columns = ['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3sj7WsydE63",
        "colab_type": "text"
      },
      "source": [
        "In the second line, we assigning a column name called label to the predictors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "527Ko5t7c-lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors_model['coeff'] = model.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG6Yuw3Legci",
        "colab_type": "text"
      },
      "source": [
        "In this line of code we are taking the coefficients from the Lasso model we built earlier and then assigning a column next to the predictors with all the coefficients. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFa9MTKReZIr",
        "colab_type": "code",
        "outputId": "1e77ae8a-9292-49d3-82b6-754edbef6859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "predictors_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B01001008</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B01001009</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B01001010</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B01001011</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B01001012</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>B19001013</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>B19001014</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>B19001015</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>B19001016</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>B19001017</td>\n",
              "      <td>1.483435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>182 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         label     coeff\n",
              "0    B01001008  0.000000\n",
              "1    B01001009  0.000000\n",
              "2    B01001010  0.000000\n",
              "3    B01001011  0.000000\n",
              "4    B01001012  0.000000\n",
              "..         ...       ...\n",
              "177  B19001013  0.000000\n",
              "178  B19001014  0.000000\n",
              "179  B19001015  0.000000\n",
              "180  B19001016  0.000000\n",
              "181  B19001017  1.483435\n",
              "\n",
              "[182 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47vGQhLqfV6z",
        "colab_type": "code",
        "outputId": "0a8f6b0d-adee-4f20-afd2-704915a6ecfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "for index, row in predictors_model.iterrows():\n",
        "    if row['coeff'] > 0:\n",
        "        print(row.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B01001014' 0.8558761066941788]\n",
            "['B01001036' 2.5053482381631653]\n",
            "['B01001037' 0.8892493223320962]\n",
            "['B01001038' 1.5316387928880384]\n",
            "['B02001005' 0.41252295298457853]\n",
            "['B13014026' 0.48004105312075906]\n",
            "['B13014027' 0.6978957445987839]\n",
            "['B13016001' 875149895.329212]\n",
            "['B19001017' 1.4834348068681533]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TuqSjuKfawI",
        "colab_type": "text"
      },
      "source": [
        "Here we are running a for loop that iterates through all the rows and searches for coefficients greater than 0. Then it prints the values that are greater than 0. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjpZUvSTMEDw",
        "colab_type": "text"
      },
      "source": [
        "Question 2: Based on the output above, women aged 15-50 who have given birth in the past 12 months have the most impact in predicting sales of Bobo bars. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULOoTl_-PFvC",
        "colab_type": "text"
      },
      "source": [
        "Question 3: The two census variables that predict the most sales of bobo bars are 1. Women aged 15-50 who have given birth in the past 12 months. \n",
        "    2. Females aged 30-34"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k4pyRvhQaGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0H-xe7xP7Kh",
        "colab_type": "code",
        "outputId": "6ddaceb4-7f54-4d2b-a834-efbca4912755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
        "print ('training data MSE')\n",
        "print(train_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data MSE\n",
            "22025.491066757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z2sKBqvRHES",
        "colab_type": "code",
        "outputId": "19e5d36b-80c9-4fda-bb14-d83007b8a3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
        "print ('test data MSE')\n",
        "print(test_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test data MSE\n",
            "41549.54803776253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CbSV1sZUwea",
        "colab_type": "text"
      },
      "source": [
        "Question 4: The mean squared error tells us how close the regression line is to a set of points. The larger the MSE, the further away you are from the line of best fit. In the output above, the MSE for the test data is higher than the training data, meaning that the data values are dispersed widely around the mean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__eI4jqkZfIr",
        "colab_type": "code",
        "outputId": "31ad87ad-08f6-4e20-ab08-eab2f86ac934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "rsquared_train=model.score(pred_train,tar_train)\n",
        "print ('training data R-square')\n",
        "print(rsquared_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data R-square\n",
            "0.2400221219784492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1kJbSktZnyB",
        "colab_type": "code",
        "outputId": "4aab5a22-74de-41fc-9645-a0ddeb13d1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "rsquared_test=model.score(pred_test,tar_test)\n",
        "print ('test data R-square')\n",
        "print(rsquared_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test data R-square\n",
            "0.1758628512005107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjzTUk39aBma",
        "colab_type": "text"
      },
      "source": [
        "Question 5: After building the Lasso model, only 9 variables out of the 180 given had any significance towards predicting sales. A few of the variables have strong impact, such as Women aged 15-50 and females aged 30-34, however with the large amount of variables having little to no impact, it shows that overall most of the census data doesn't have much of an impact towards predicting sales numbers. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DTeQYaXagx-",
        "colab_type": "code",
        "outputId": "8671b667-4b5a-4e79-9ebd-0eb5a9c97809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"y interecept:\")\n",
        "print(model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y interecept:\n",
            "22.19738813257551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2sQcXfdaiJB",
        "colab_type": "text"
      },
      "source": [
        "Question 6: The baseline sales number is 22, which is the value in which the fitted line crosses the y axis. Without any input parameters in the predictor variables, these are the predicted sales numbers."
      ]
    }
  ]
}